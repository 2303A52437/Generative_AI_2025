{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGWwCD8XydMULd/rbfnfME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52437/Generative_AI_2025/blob/main/2303A52437_4_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a linear activation function in the output layer.\n",
        "\n",
        "•  Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.\n",
        "\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "\n",
        "• Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        "output with deployed ANN model"
      ],
      "metadata": {
        "id": "UspThpKmHh5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYp297VIDT7P"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[0.1, 0.2, 0.3],\n",
        "                    [0.2, 0.3, 0.4],\n",
        "                    [0.3, 0.4, 0.5],\n",
        "                    [0.5, 0.6, 0.7],\n",
        "                    [0.1, 0.3, 0.5],\n",
        "                    [0.2, 0.4, 0.6],\n",
        "                    [0.3, 0.5, 0.7],\n",
        "                    [0.4, 0.6, 0.8],\n",
        "                    [0.5, 0.7, 0.1]])\n",
        "y_train = np.array([0.14, 0.20, 0.26, 0.38, 0.22, 0.28, 0.34, 0.40, 0.22])"
      ],
      "metadata": {
        "id": "WY1jKMccFE5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.random.rand(3)\n",
        "bias = np.random.rand()\n",
        "learning_rate = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "eUF3Yb5PIP-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation(x):\n",
        "  return x\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "  return np.mean((y_true - y_pred)**2)\n",
        "for _ in range(epochs):\n",
        "  #Forward Pass\n",
        "  y_pred = linear_activation(np.dot(X_train, weights) + bias)\n",
        "\n",
        "  #error\n",
        "  error = y_train - y_pred\n",
        "\n",
        "  #Backward pass\n",
        "  d_weights = -2 * np.dot(X_train.T, error) / len(X_train)\n",
        "  d_bias = -2 * np.mean(error)\n",
        "\n",
        "  #update weights\n",
        "  weights -= learning_rate * d_weights\n",
        "  bias -= learning_rate * d_bias\n",
        "\n",
        "print(f\"Trained weights: {weights}\")\n",
        "print(f\"Trained bias: {bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabbESBUI4LH",
        "outputId": "96a52530-e33c-49d5-b80e-61397166d810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained weights: [0.28720059 0.14183529 0.26613467]\n",
            "Trained bias: -0.011751295927699086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "X_test = np.array([[0.6, 0.7, 0.8],\n",
        "                   [0.7, 0.8, 0.9]])\n",
        "\n",
        "y_test = np.array([0.44, 0.50])\n",
        "\n",
        "# Calculate Mean Square Error for training data\n",
        "y_train_pred = linear_activation(np.dot(X_train, weights) + bias)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Calculate Mean Square Error for testing data\n",
        "y_test_pred = linear_activation(np.dot(X_test, weights) + bias)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"MSE Train: {mse_train}\")\n",
        "print(f\"MSE test: {mse_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXVIrJ4lMxja",
        "outputId": "a4a86354-d522-411e-c2b2-ed559aaf9e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.000374895206954674\n",
            "MSE test: 0.0014303953540919616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x):\n",
        "    return linear_activation(np.dot(x, weights) + bias)\n",
        "\n",
        "# Read input data from the user\n",
        "x1 = float(input(\"Enter value for x1: \"))\n",
        "x2 = float(input(\"Enter value for x2: \"))\n",
        "x3 = float(input(\"Enter value for x3: \"))\n",
        "\n",
        "# Predict output using the trained model\n",
        "new_input = np.array([x1, x2, x3])\n",
        "predicted_output = predict(new_input)\n",
        "\n",
        "print(f\"Predicted output: {predicted_output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jurL05eQNPdi",
        "outputId": "5a63b366-4098-49bf-8adf-c0bf606603ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter value for x1: 0.5\n",
            "Enter value for x2: 0.6\n",
            "Enter value for x3: 0.4\n",
            "Predicted output: 0.32340403627138725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a sigmoid activation function shown in the equation 1 in the output layer.\n",
        "f (x) =  1 /\n",
        "1 + e−x"
      ],
      "metadata": {
        "id": "4zxnCBPdOZEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "ocUEZJhsOY4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[0.1, 0.2, 0.3],\n",
        "                    [0.2, 0.3, 0.4],\n",
        "                    [0.3, 0.4, 0.5],\n",
        "                    [0.5, 0.6, 0.7],\n",
        "                    [0.1, 0.3, 0.5],\n",
        "                    [0.2, 0.4, 0.6],\n",
        "                    [0.3, 0.5, 0.7],\n",
        "                    [0.4, 0.6, 0.8],\n",
        "                    [0.5, 0.7, 0.1]])\n",
        "y_train = np.array([[0.5349], [0.5498], [0.5646], [0.5939], [0.5548], [0.5695], [0.5842], [0.5987], [0.5548]])"
      ],
      "metadata": {
        "id": "SBqKyZtCO94t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.random.rand(3, 1)\n",
        "bias = np.random.rand(1)\n",
        "learning_rate = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "tK6wAuXYPggl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(epochs):\n",
        "    # Forward pass\n",
        "    z = np.dot(X_train, weights) + bias\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Calculate error\n",
        "    error = y_train - y_pred\n",
        "\n",
        "    # Backward pass (calculate gradients)\n",
        "    d_weights = np.dot(X_train.T, error * sigmoid_derivative(y_pred))\n",
        "    d_bias = np.sum(error * sigmoid_derivative(y_pred))\n",
        "\n",
        "    # Update weights and bias\n",
        "    weights += learning_rate * d_weights\n",
        "    bias += learning_rate * d_bias\n",
        "\n",
        "print(f\"Trained weights: {weights}\")\n",
        "print(f\"Trained bias: {bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jubhlWcPkiZ",
        "outputId": "11bbda2c-feac-4af5-849e-131c793bc97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained weights: [[-0.16279495]\n",
            " [ 0.48358928]\n",
            " [ 0.13147568]]\n",
            "Trained bias: [0.03782431]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[0.6, 0.7, 0.8],\n",
        "                   [0.7, 0.8, 0.9]])\n",
        "\n",
        "y_test = np.array([[0.6083],\n",
        "                   [0.6225]])\n",
        "def mean_square_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "y_train_pred = sigmoid(np.dot(X_train, weights) + bias)\n",
        "\n",
        "mse_train = mean_square_error(y_train, y_train_pred)\n",
        "\n",
        "y_test_pred = sigmoid(np.dot(X_test, weights) + bias)\n",
        "\n",
        "mse_test = mean_square_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"MSE Training Data: {mse_train}\")\n",
        "print(f\"MSE for Testing Data: {mse_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ6Ob6iqROkl",
        "outputId": "c20ac9db-73a2-4962-a79b-7b2635de925e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Training Data: 7.593738136811198e-05\n",
            "MSE for Testing Data: 0.00023308352018887904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x):\n",
        "    return sigmoid(np.dot(x, weights) + bias)\n",
        "\n",
        "# Read input data from the user\n",
        "x1 = float(input(\"Enter value for x1: \"))\n",
        "x2 = float(input(\"Enter value for x2: \"))\n",
        "x3 = float(input(\"Enter value for x3: \"))\n",
        "new_input = np.array([x1, x2, x3])\n",
        "predicted_output = predict(new_input)\n",
        "\n",
        "print(f\"Predicted output: {predicted_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2YMwy9zSiHN",
        "outputId": "a9bbbb95-938c-4037-f23a-ae5c64421778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter value for x1: 11.7\n",
            "Enter value for x2: 24.5\n",
            "Enter value for x3: 30\n",
            "Predicted output: [0.9999991]\n"
          ]
        }
      ]
    }
  ]
}