{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1n0Z71IOY9mqDq63W+wkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52437/Generative_AI_2025/blob/main/2303A52437_01_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Question**\n",
        "\n",
        "1. (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "\n",
        "YActual:[ 20 , 30 , 40 , 50 , 60]\n",
        "\n",
        "YPred: [20.5 , 30.3 , 40.2 , 50.6 , 60.7]"
      ],
      "metadata": {
        "id": "miYEJ19AtDaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7z7R8_3dso7c"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actual and Predicted values**"
      ],
      "metadata": {
        "id": "WcpLCvgOuhob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual = [20, 30, 40, 50, 60]\n",
        "y_pred = [20.5, 30.3, 40.2, 50.6, 60.7]"
      ],
      "metadata": {
        "id": "jVnG_e8othSb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mean Absolute Error (MAE)**"
      ],
      "metadata": {
        "id": "5Rwve_l-uokV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(y_actual, y_pred):\n",
        "    return np.mean(np.abs(np.array(y_actual) - np.array(y_pred)))\n",
        "mae_result = mae(y_actual, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QicSfIf8t7by",
        "outputId": "d482eb7d-5e51-4d3a-9426-9e793c6d5eee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mean Squared Error (MSE)**"
      ],
      "metadata": {
        "id": "6RLtQZzgvFxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_actual, y_pred):\n",
        "  return np.mean((np.array(y_actual)-np.array(y_pred))**2)\n",
        "mse_result = mse(y_actual, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IOIFxuJvKvT",
        "outputId": "ba99c363-6e35-41ab-bab7-489f3854aa7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.24600000000000147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Root Mean Squared Error (RMSE)**"
      ],
      "metadata": {
        "id": "ZJwUYayMviDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_actual, y_pred):\n",
        "  return np.sqrt(mse(y_actual, y_pred))\n",
        "rmse_result = rmse(y_actual, y_pred)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "figC0_4Tvf1G",
        "outputId": "d7f4829e-0b3e-4526-f7e2-6eafa5f6eb6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparison with libraries (sklearn)**"
      ],
      "metadata": {
        "id": "T2i8nq_-wg9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mae_sklearn = mean_absolute_error(y_actual, y_pred)\n",
        "mse_sklearn = mean_squared_error(y_actual, y_pred)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "print(f\"\\nComparison with scikit-learn:\")\n",
        "print(f\"MAE (sklearn): {mae_sklearn}\")\n",
        "print(f\"MSE (sklearn): {mse_sklearn}\")\n",
        "print(f\"RMSE (sklearn): {rmse_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHzpE_yqwk_D",
        "outputId": "fbe8b070-a6c5-4a10-b83c-52f45a05d3f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with scikit-learn:\n",
            "MAE (sklearn): 0.4600000000000016\n",
            "MSE (sklearn): 0.24600000000000147\n",
            "RMSE (sklearn): 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Question**\n",
        "\n",
        "2. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.Actual values and deep learning model predicted values are shown in Table 2. Also compare the results with outcome of libraries\n",
        "\n",
        "YActual: [ 0 , 0 , 0 , 0 , 0 ]\n",
        "\n",
        "YPred: [0 , 0 , 1 , 2 , 2 ]\n"
      ],
      "metadata": {
        "id": "Kxkm_Z6rwtXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Actual and predicted values**\n"
      ],
      "metadata": {
        "id": "uONsjm_2xYHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "w2nBp33twrJU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual =np.array([0, 0, 0, 0, 0])\n",
        "y_pred = np.array([0, 0, 1, 2, 2])"
      ],
      "metadata": {
        "id": "VPS67D3Vx1I-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Absolute Error (MAE)**"
      ],
      "metadata": {
        "id": "qiJ20Jb9yV-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(y_actual, y_pred):\n",
        "    return np.mean(np.abs(np.array(y_actual) - np.array(y_pred)))\n",
        "mae_res = mae(y_actual, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRzum_IwyVMj",
        "outputId": "0f8e519c-2b2a-40bb-bc44-67022da1b8f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Squared Error (MSE)**"
      ],
      "metadata": {
        "id": "RT6unAdry421"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_actual, y_pred):\n",
        "  return np.mean(np.square(y_actual-y_pred))\n",
        "mse_res = mse(y_actual, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse_res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th3Y7Nj2y3AG",
        "outputId": "ef4c840d-dd83-49f3-9066-2556cf6aeb1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Root Mean Squared Error (RMSE)**"
      ],
      "metadata": {
        "id": "5RIURZfFzknf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_actual, y_pred):\n",
        "  return np.sqrt(mse(y_actual, y_pred))\n",
        "rmse_result = rmse(y_actual, y_pred)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYmoE3kBziJf",
        "outputId": "7015b295-7618-404c-989b-c6f538cefb98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 1.3416407864998738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison with libraries (sklearn)**\n"
      ],
      "metadata": {
        "id": "kTXOBzpEzu7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_sklearn = mean_absolute_error(y_actual, y_pred)\n",
        "mse_sklearn = mean_squared_error(y_actual, y_pred)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "print(f\"\\nComparison with scikit-learn:\")\n",
        "print(f\"MAE (sklearn): {mae_sklearn}\")\n",
        "print(f\"MSE (sklearn): {mse_sklearn}\")\n",
        "print(f\"RMSE (sklearn): {rmse_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmYydycQzywi",
        "outputId": "e5674975-8a60-4837-9e8e-baf454df6abd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with scikit-learn:\n",
            "MAE (sklearn): 1.0\n",
            "MSE (sklearn): 1.8\n",
            "RMSE (sklearn): 1.3416407864998738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Additional metrics relevant for classification(since the data seems binary)**\n"
      ],
      "metadata": {
        "id": "Sxom1sakz4ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix # Import confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_actual, y_pred)\n",
        "precision = precision_score(y_actual, y_pred, average='micro')\n",
        "recall = recall_score(y_actual, y_pred, average='micro')\n",
        "f1 = f1_score(y_actual, y_pred, average='micro')\n",
        "\n",
        "print(f\"\\nClassification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-_J5iJTz2mh",
        "outputId": "6043212e-a118-459a-c0c7-9d36509acb46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Metrics:\n",
            "Accuracy: 0.4\n",
            "Precision: 0.4\n",
            "Recall: 0.4\n",
            "F1 Score: 0.4\n"
          ]
        }
      ]
    }
  ]
}